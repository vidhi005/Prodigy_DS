{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import polars as pl\n",
    "import vaex as vx\n",
    "#import pyarrow.parquet as pq\n",
    "#import dask.dataframe as dd\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import CategoricalNB, BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, label_binarize\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"/kaggle/input/us-accidents/US_Accidents_March23.csv\",index_col = 0,parse_dates=['Start_Time','End_Time'],infer_datetime_format=True)\n",
    "df_base = df_original.copy()\n",
    "df_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj = df_base.select_dtypes(include = ['object'])\n",
    "df_num = df_base.select_dtypes(exclude = ['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obj_nunique = df_obj.nunique().reset_index()\n",
    "df_obj_nunique.columns = ['columns_name','unique_value_count']\n",
    "df_obj_nunique['unique_ratio'] = df_obj_nunique['unique_value_count']/df_base.shape[0]\n",
    "df_obj_nunique.sort_values(by='unique_ratio', ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_nunique = df_num.nunique().reset_index()\n",
    "df_num_nunique.columns = ['columns_name','unique_value_count']\n",
    "df_num_nunique['unique_ratio'] = df_num_nunique['unique_value_count']/df_base.shape[0]\n",
    "df_num_nunique.sort_values(by='unique_ratio', ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_num.isnull().sum(axis = 0).reset_index()\n",
    "df_missing.columns = ['columns_name', 'missing_count']\n",
    "df_missing['missing_ratio'] = df_missing['missing_count']/df_base.shape[0]\n",
    "df_missing.query('missing_ratio > 0').sort_values(by = 'missing_ratio',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_obj.isnull().sum(axis = 0).reset_index()\n",
    "df_missing.columns = ['columns_name', 'missing_count']\n",
    "df_missing['missing_ratio'] = df_missing['missing_count']/df_base.shape[0]\n",
    "df_missing.query('missing_ratio > 0').sort_values(by = 'missing_ratio',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_base[[col for col in df_base.columns if col not in ['End_Lat','End_Lng', 'Precipitation(in)', 'Wind_Chill(F)', 'Turning_Loop', 'Country']]]\n",
    "df_clean_obj = df_clean.select_dtypes(include = ['object'])\n",
    "df_clean_num = df_clean.select_dtypes(exclude = ['object','datetime64']) #Excluding date time since it has no null values and imputation doesn't work on this dt\n",
    "len(df_clean_obj.columns)+len(df_clean_num.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_imputer = SimpleImputer(strategy = 'most_frequent')\n",
    "df_cl_obj = pd.DataFrame(obj_imputer.fit_transform(df_clean_obj),columns=df_clean_obj.columns, index=df_clean_obj.index)\n",
    "# df_cl_obj.head()\n",
    "num_imputer = SimpleImputer(strategy = 'mean')\n",
    "df_cl_num = pd.DataFrame(num_imputer.fit_transform(df_clean_num),columns=df_clean_num.columns, index=df_clean_num.index)\n",
    "# df_cl_num.head()\n",
    "print((df_clean_obj.County == df_cl_obj.County).all()) \n",
    "# Verify imputation didn't messed up entries, by comparing non null columns \n",
    "# If non-null columns stay same as the original db for every entry we are good.\n",
    "\n",
    "print((df_clean_num['Distance(mi)'] == df_cl_num['Distance(mi)']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_obj = pd.concat([df_cl_obj,df_base.loc[:,['Start_Time','End_Time']]],axis = 1) #Setting the original obj_df with imputed one\n",
    "df_clean_num = df_cl_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_1 = {'Day':1, 'Night': 0}\n",
    "times = [\"Civil_Twilight\",\"Nautical_Twilight\",\"Astronomical_Twilight\",\"Sunrise_Sunset\"]\n",
    "df_clean_obj[times] = (df_clean_obj[times].replace(mapping_1))\n",
    "\n",
    "mapping_2 = {'US/Eastern':1,'US/Pacific':2,'US/Central':3,'US/Mountain':4}\n",
    "df_clean_obj[['Timezone']] = (df_clean_obj[[\"Timezone\"]].replace(mapping_2))\n",
    "# Extract year, month, day, hour and weekday\n",
    "df_clean_obj['Year'] = (df_clean_obj['Start_Time'].dt.year).astype('uint16')\n",
    "df_clean_obj['Month'] = (df_clean_obj['Start_Time'].dt.strftime('%b')).astype('category')\n",
    "df_clean_obj['Day'] = (df_clean_obj['Start_Time'].dt.day).astype('uint8')\n",
    "df_clean_obj['Hour'] = (df_clean_obj['Start_Time'].dt.hour).astype('uint8')\n",
    "df_clean_obj['Min'] = (df_clean_obj['Start_Time'].dt.minute).astype('float32')\n",
    "df_clean_obj['Weekday'] = (df_clean_obj['Start_Time'].dt.strftime(\"%a\")).astype('category')\n",
    "\n",
    "# Extract the amount of time in the unit of mins for each accident, rounded to the nearest integer\n",
    "td = \"Time_Duration(min)\"\n",
    "df_clean_obj[td] = (round((df_clean_obj['End_Time'] - df_clean_obj['Start_Time'])/np.timedelta64(1,'m'),3)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_outliers = df_clean_obj[td]<=0\n",
    "\n",
    "# Set outliers to NAN\n",
    "df_clean_obj[neg_outliers] = np.nan\n",
    "\n",
    "# **Drop rows with negative td**\n",
    "df_clean_obj.dropna(subset = [td], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dtypes = {'Source':'category',\n",
    "        'Description':'string', \n",
    "        'Street':'category',\n",
    "        'City':'category', \n",
    "        'County':'category',\n",
    "        'State':'category', \n",
    "        'Zipcode':'category',\n",
    "        'Timezone':'uint8',\n",
    "        'Airport_Code':'category',\n",
    "        'Weather_Timestamp':'string',\n",
    "        'Wind_Direction':'category',\n",
    "        'Weather_Condition':'string',\n",
    "        'Sunrise_Sunset':'bool',\n",
    "        'Civil_Twilight':'bool',\n",
    "        'Nautical_Twilight':'bool', \n",
    "        'Astronomical_Twilight':'bool',\n",
    "        'Start_Time':'datetime64[ns]',\n",
    "        'End_Time':'datetime64[ns]',\n",
    "        'Year':'uint16',\n",
    "        'Day':'uint8',\n",
    "        'Hour':'uint8',\n",
    "        'Min': 'uint8',\n",
    "        'Weekday': 'category',\n",
    "        'Time_Duration(min)':'float32',\n",
    "        'Month':'category'}\n",
    "\n",
    "num_dtypes = { 'Severity':'uint8',\n",
    "            'Start_Lat': 'float32',\n",
    "            'Start_Lng': 'float32',\n",
    "            'Distance(mi)': 'float32',\n",
    "            'Temperature(F)': 'float32','Humidity(%)': 'float32',\n",
    "            'Pressure(in)': 'float32',\n",
    "            'Visibility(mi)': 'float32',\n",
    "            'Wind_Speed(mph)': 'float32',\n",
    "            'Amenity':'bool',\n",
    "            'Bump':\"bool\",\n",
    "            'Crossing':'bool',\n",
    "            'Give_Way':'bool',\n",
    "            'Junction':'bool',\n",
    "            'No_Exit':'bool',\n",
    "            'Railway':'bool',\n",
    "            'Roundabout':'bool',\n",
    "            'Station':'bool', \n",
    "            'Stop':'bool',\n",
    "            'Traffic_Calming':'bool',\n",
    "            'Traffic_Signal':'bool',\n",
    "             }\n",
    "df_clean_obj = df_clean_obj.astype(obj_dtypes)\n",
    "df_clean_num = df_clean_num.astype(num_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.concat([df_clean_num,df_clean_obj],axis = 1)\n",
    "df_clean.head()\n",
    "df_clean.shape\n",
    "df_clean.describe()\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df_clean.isnull().sum(axis = 0).reset_index()\n",
    "df_missing.columns = ['columns_name', 'missing_count']\n",
    "df_missing['missing_ratio'] = df_missing['missing_count']/df_clean.shape[0]\n",
    "df_missing['data_type'] = [df_clean[col].dtypes for col in df_missing.columns_name[:]]\n",
    "df_missing.query('missing_ratio > 0').sort_values(by = ['missing_ratio','data_type'], ascending = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "state_acc_counts = pd.DataFrame(df_clean['State'].value_counts())\n",
    "z = state_acc_counts.values.flatten()\n",
    "x = state_acc_counts.index.to_list()\n",
    "fig = go.Figure(data = go.Choropleth(locations = x, z = z, locationmode = \"USA-states\", colorscale = 'ylorrd'))\n",
    "\n",
    "fig.update_layout(title_text = \"Number of Accidents for each State in US\", geo_scope = \"usa\")\n",
    "fig.show()\n",
    "## Observing which states have most accidents\n",
    "fig,axs = plt.subplots(figsize = (10,6))\n",
    "\n",
    "x = state_acc_counts[0:15].index.to_list()\n",
    "y = state_acc_counts[0:15].values.flatten()\n",
    "\n",
    "sns.barplot(x=x, y = y, palette='rainbow')\n",
    "axs.tick_params(axis = 'x', rotation = 90)\n",
    "axs.set_ylabel(\"Number of Accidents\")\n",
    "axs.set_xlabel(\"States\")\n",
    "plt.title(\"Top 15 States with Highest Number of Accidents\")\n",
    "plt.savefig(\"Top_15_States_Accidents.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_acc_counts = pd.DataFrame(df_clean['City'].value_counts()).reset_index()\n",
    "city_acc_counts.columns = ['City',\"Number of Accidents\"]\n",
    "city_acc_counts.sort_values(by = 'Number of Accidents', ascending = False,inplace = True)\n",
    "x = city_acc_counts['City'][:15].to_list()\n",
    "y = city_acc_counts[\"Number of Accidents\"][:15]\n",
    "## Observing Top 20 cities have most accidents\n",
    "fig,axs = plt.subplots(figsize = (10,6))\n",
    "sns.barplot(x = x,y=y, ax = axs, palette = 'rainbow')\n",
    "axs.tick_params(axis = 'x', rotation = 90)\n",
    "axs.set_yscale(\"log\")\n",
    "axs.set_ylabel(\"Number of Accidents\")\n",
    "axs.set_xlabel(\"Cities\")\n",
    "plt.title(\"Top 15 Cities with Highest Number of Accidents\")\n",
    "plt.savefig(\"Top_15_Cities_Accidents.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_acc_counts = pd.DataFrame(df_clean['Weekday'].value_counts()).reset_index()\n",
    "weekday_acc_counts.columns = [\"Day\",\"Number of Accidents\"]\n",
    "days = weekday_acc_counts['Day']\n",
    "acc = weekday_acc_counts[\"Number of Accidents\"]\n",
    "dc = {days[i]:acc[i] for i in range(7)}\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.title(\"Number of accidents for each weekday\")\n",
    "sns.barplot(x=list(dc.keys()), y = list(dc.values()),palette='rainbow')\n",
    "plt.xlabel(\"Weekday\")\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.savefig(\"Accidents_Weekday_Distribution.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_clean[\"Weather_Condition\"].value_counts()[:15]\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.title(\"Histogram distribution of the top 15 weather conditions\")\n",
    "sns.barplot(x = counts.index,y= counts.values)\n",
    "plt.xlabel(\"Weather Condition\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.savefig(\"Weather_Accident_Distribution.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\") + [\"-\"]\n",
    "severity_levels = [1, 2, 3, 4]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, severity in enumerate(severity_levels):\n",
    "    ax = axs[i]\n",
    "    df_desc = df_clean[df_clean[\"Severity\"] == severity][\"Description\"]\n",
    "\n",
    "    # Split the description using vectorized operations\n",
    "    df_words = df_desc.str.cat(sep=' ').lower().split()\n",
    "\n",
    "    # Count the words and filter out stopwords\n",
    "    counts = pd.Series(df_words).value_counts().loc[lambda x: ~x.index.isin(stop)][:10]\n",
    "\n",
    "    # Plot the barplot\n",
    "    sns.barplot(x=counts.values, y=counts.index, orient=\"h\", ax=ax, palette='rainbow')\n",
    "    ax.set_title(f\"Top 10 words used to describe an accident with severity {severity}\")\n",
    "    ax.set_xlabel(\"Value\")\n",
    "    ax.set_ylabel(\"Word\")\n",
    "\n",
    "plt.savefig(\"Frequent_Words_PerSeverityLevel.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize = (10,6))\n",
    "sns.countplot(x = 'Severity', data = df_clean, ax = axs, order=df_clean.Severity.value_counts().index, palette='rainbow')\n",
    "axs.tick_params(axis = 'x', rotation = 0)\n",
    "#axs.set_yscale(\"log\")\n",
    "axs.set_ylabel(\"Accident Count\")\n",
    "\n",
    "\n",
    "plt.title(\"Number of Accidents per Severity Level\")\n",
    "plt.savefig(\"Num_Accidents_Per_Severity_Level.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(figsize = (10,6))\n",
    "sns.countplot(x = 'Source', data = df_clean, ax = axs, order=df_clean.Source.value_counts().index, palette='rainbow')\n",
    "axs.tick_params(axis = 'x', rotation = 0)\n",
    "#axs.set_yscale(\"log\")\n",
    "axs.set_ylabel(\"Accident Count\")\n",
    "\n",
    "plt.title(\"Number of Accidents per Source Level\")\n",
    "plt.savefig(\"Accidents_Per_Source_Level.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_clean.corr()\n",
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(corr_matrix,annot=True,linewidths=1,linecolor='k',square=True,mask=False, vmin=-1, vmax=1,cbar_kws={\"orientation\": \"vertical\"},cbar=True)\n",
    "plt.gca().patch.set(hatch=\"X\", edgecolor=\"#666\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [col for col in df_clean.columns if col not in ['Severity'] if df_clean[col].dtype in ['float32','uint8','bool','uint16']]\n",
    "\n",
    "labels = []\n",
    "values = []\n",
    "for col in x_cols:\n",
    "    labels.append(col)\n",
    "    values.append(np.corrcoef(df_clean[col].values, df_clean.Severity.values)[0,1])\n",
    "corr_df = pd.DataFrame({'col_labels':labels, 'corr_values':values})\n",
    "corr_df = (corr_df.sort_values(by='corr_values',ascending = False)).reset_index()\n",
    "corr_df\n",
    "\n",
    "ind = np.arange(len(labels))\n",
    "width = 0.9\n",
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "rects = ax.barh(ind, np.array(corr_df.corr_values.values), color='orange')\n",
    "ax.set_yticks(ind)\n",
    "ax.set_yticklabels(corr_df.col_labels.values, rotation='horizontal')\n",
    "ax.set_xlabel(\"Correlation coefficient\")\n",
    "ax.set_title(\"Correlation coefficient of the variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_corr_features = corr_df[(corr_df.corr_values>=-0.01) & (corr_df.corr_values<=0.01)].col_labels[:]\n",
    "less_corr = less_corr_features.to_list()\n",
    "less_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_clean.groupby(['Year', 'Severity'])['Start_Lat'].count()\n",
    "\n",
    "# Convert the result to a DataFrame\n",
    "df_pivot = grouped.reset_index()\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df_pivot = df_pivot.pivot(index='Year', columns='Severity', values='Start_Lat')\n",
    "\n",
    "# Display the pivoted DataFrame\n",
    "#print(df_pivot)\n",
    "\n",
    "# Plot the stacked bar chart\n",
    "ax = df_pivot.plot.bar(stacked=True)\n",
    "\n",
    "# Set the y-axis scale to logarithmic\n",
    "ax.set_yscale(\"log\")\n",
    "# Set the title and axis labels\n",
    "plt.title(\"Accidents Organized by Severity Level per Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Accidents\")\n",
    "plt.savefig(\"Accidents_Organized_by_Severity_Level_per_Year.png\",bbox_inches = 'tight', dpi = 300)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_cols = less_corr + [\"Description\",'Street','County','Zipcode','State','Airport_Code','Weather_Timestamp','Start_Time','End_Time']\n",
    "dropped_cols    \n",
    "df_clean = df_clean.drop(dropped_cols,axis = 1)\n",
    "df_clean.head()\n",
    "df_clean.describe().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows:\", len(df_clean.index))\n",
    "df_clean.drop_duplicates(inplace=True)\n",
    "print(\"Number of rows after drop of duplicates:\", len(df_clean.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean[\"Pressure(in)\"] != 0]\n",
    "len(df_clean.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_weather = (df_clean[\"Weather_Condition\"].unique())\n",
    "\n",
    "print(len(unique_weather))\n",
    "print(list((unique_weather)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Rain|Drizzle|Shower|Precipitation\", na=False), \"Weather_Condition\"] = \"Rain\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Cloudy|Overcast\", na=False), \"Weather_Condition\"] = \"Cloudy\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Snow|Sleet|Wintry\", na=False), \"Weather_Condition\"] = \"Snow\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Fog|Mist\", na=False), \"Weather_Condition\"] = \"Fog\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Clear|Fair\", na=False), \"Weather_Condition\"] = \"Clear\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Smoke|Volcanic Ash\", na=False), \"Weather_Condition\"] = \"Smoke\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Thunder|T-Storm\", na=False), \"Weather_Condition\"] = \"Thunderstorm\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Sand|Dust\", na=False), \"Weather_Condition\"] = \"Sand\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Wind|Squalls\", na=False), \"Weather_Condition\"] = \"Windy\"\n",
    "df_clean.loc[df_clean[\"Weather_Condition\"].str.contains(\"Hail|Pellets\", na=False), \"Weather_Condition\"] = \"Hail\"\n",
    "\n",
    "df_clean[\"Weather_Condition\"] = df_clean[\"Weather_Condition\"].astype('category')\n",
    "df_clean.Weather_Condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"Wind_Direction\"].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.isna().sum()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.describe().round(3)\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_counts = df_clean[\"Severity\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Histogram for the severity\")\n",
    "sns.barplot(x = severity_counts.index,y=severity_counts.values)\n",
    "plt.xlabel(\"Severity\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.savefig(\"UnBalanced_Severity.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(df_clean[df_clean[\"Severity\"]==1].index)\n",
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame()\n",
    "for i in range(1,5):\n",
    "    S = df_clean[df_clean[\"Severity\"]==i]\n",
    "    x = pd.concat([x,S.sample(size, random_state=42)],axis = 0)\n",
    "df_balanced = x\n",
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_counts = df_balanced[\"Severity\"].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Histogram for the severity\")\n",
    "sns.barplot(x = severity_counts.index,y=severity_counts.values)\n",
    "plt.xlabel(\"Severity\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.savefig(\"Balanced_Severity.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = (df_balanced.select_dtypes(include = ['float32','uint8','uint16',],exclude = ['bool']).columns).to_list()\n",
    "cat_features = (df_balanced.select_dtypes(exclude = ['float32','uint8','uint16','bool','int64']).columns).to_list()\n",
    "bool_features = (df_balanced.select_dtypes(include= ['bool']).columns).to_list()\n",
    "cat_features,num_features,bool_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features.remove(\"Severity\")\n",
    "scaler = MinMaxScaler()\n",
    "#features = ['Temperature(F)','Distance(mi)','Humidity(%)','Pressure(in)','Visibility(mi)','Wind_Speed(,'Start_Lng','Start_Lat','Year', 'Month','Weekday','Day','Hour','Minute']\n",
    "df_balanced[num_features] = scaler.fit_transform(df_balanced[num_features])\n",
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.replace([True, False], [1, 0])\n",
    "df_balanced[bool_features] = df_balanced[bool_features].astype('uint8')\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_p = \"test.pickle\"\n",
    "df_balanced.to_pickle(name_p)\n",
    "df_balanced = pd.read_pickle(name_p)\n",
    "onehot_cols = list(set(cat_features) - set([\"City\"]))\n",
    "onehot_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced[onehot_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.get_dummies(df_balanced, columns=onehot_cols, drop_first=True)\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_counts = df_balanced[\"City\"].value_counts()\n",
    "city_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_count_cities = city_counts[city_counts == 0].index\n",
    "instances = df_balanced[df_balanced[\"City\"].isin(zero_count_cities)]\n",
    "instances.sort_values(by = [\"City\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_counts[city_counts > 0]\n",
    "city_counts[ (0<city_counts) & (city_counts < 6)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced[\"city_mean_encoded\"] = (df_balanced.groupby(\"City\")[\"Severity\"].transform(\"mean\")).astype('float32')\n",
    "\n",
    "df_balanced[[\"City\", \"Severity\", \"city_mean_encoded\"]].sort_values(by = \"Severity\",ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_balanced.copy()\n",
    "y = X.pop('Severity')\n",
    "from category_encoders import MEstimateEncoder\n",
    "\n",
    "# Create the encoder instance. Choose m to control noise.\n",
    "encoder = MEstimateEncoder(cols=[\"City\"], m = 3)\n",
    "\n",
    "# Fit the encoder on the encoding split.\n",
    "encoder.fit(X, y)\n",
    "\n",
    "# Encode the Zipcode column to create the final training data\n",
    "X_train = encoder.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=90)\n",
    "ax = sns.countplot(x = y, palette= 'rainbow')\n",
    "ax = sns.kdeplot(X_train.city_mean_encoded, color='purple', ax=ax)\n",
    "ax = sns.kdeplot(X_train.City, color='red', ax=ax)\n",
    "ax.set_xlabel(\"Severity\")\n",
    "ax.set_ylim([0,10])\n",
    "ax.legend(labels=['mean_encoding', 'm_encoding'],loc = 'upper right');\n",
    "plt.savefig(\"Target_Encoding.png\",bbox_inches = 'tight', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.drop([\"City\"],inplace = True,axis = 1)\n",
    "df_balanced\n",
    "df_balanced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.to_pickle(\"final_df.pickle\")\n",
    "df_model = pd.read_pickle(\"final_df.pickle\")\n",
    "df_model.info()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
