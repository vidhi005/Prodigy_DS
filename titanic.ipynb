{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "print(test_data.shape)\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "print(train_data.shape)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sub = pd.read_csv(\"gender_submission.csv\")\n",
    "print(gen_sub.shape)\n",
    "gen_sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id=test_data[\"PassengerId\"]\n",
    "sub_id.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_train = train_data.shape[0]\n",
    "first_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_data, test_data]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary examination of the data set\n",
    "\n",
    "def check_df(dataframe, head=5):\n",
    "    print('##################### Shape #####################')\n",
    "    print(dataframe.shape)\n",
    "    print('##################### Types #####################')\n",
    "    print(dataframe.dtypes)\n",
    "    print('##################### Head #####################')\n",
    "    display(dataframe.head(head))\n",
    "    print('##################### Tail #####################')\n",
    "    display(dataframe.tail(head))\n",
    "    print('##################### NA #####################')\n",
    "    print(dataframe.isnull().sum())\n",
    "    print('##################### Quantiles #####################')\n",
    "    display(dataframe.describe([0, 0.05, 0.50, 0.95, 0.99, 1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\"Name\",\"Ticket\",\"Cabin\", 'PassengerId', 'index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_list, axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"] \n",
    "\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n",
    "                   dataframe[col].dtypes != \"O\"]\n",
    "\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n",
    "                   dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car] \n",
    "\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"] \n",
    "\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat] \n",
    "    \n",
    "    print(f\"Observations: {dataframe.shape[0]}\") \n",
    "    print(f\"Variables: {dataframe.shape[1]}\") \n",
    "    print(f'cat_cols: {len(cat_cols)}') \n",
    "    print(f'num_cols: {len(num_cols)}') \n",
    "    print(f'cat_but_car: {len(cat_but_car)}') \n",
    "    print(f'num_but_cat: {len(num_but_cat)}') \n",
    "\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car, num_but_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, num_cols, cat_but_car,  num_but_cat = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.remove(\"Survived\")\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_but_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_but_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_summary(dataframe, col_name, plot=False):\n",
    "    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n",
    "                        'Ratio': 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n",
    "    print('##########################################')\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        sns.countplot(x=dataframe[col_name], data=dataframe)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    cat_summary(df, col, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.countplot(x='Survived', data=df, palette='Set1')\n",
    "ax.grid(color='gray', alpha=0.25)  # Changing the grid lines color\n",
    "plt.title(\"Count OF Survived \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(feature):\n",
    "    survived = df[df['Survived']==1][feature].value_counts()\n",
    "    dead = df[df['Survived']==0][feature].value_counts()\n",
    "    df1 = pd.DataFrame([survived,dead])\n",
    "    df1.index = ['Survived','Dead']\n",
    "    df1.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph('Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(\"Sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph('Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_summary(dataframe, numerical_col, plot=False):\n",
    "    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n",
    "    display(dataframe[numerical_col].describe(quantiles).T)\n",
    "\n",
    "    if plot:\n",
    "        dataframe[numerical_col].hist(bins=20)\n",
    "        \n",
    "        plt.xlabel(numerical_col)\n",
    "        plt.title(numerical_col)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    num_summary(df, col, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_summary_with_cat(dataframe, target, categorical_col, plot=False):\n",
    "    print(pd.DataFrame({'TARGET_MEAN': dataframe.groupby(categorical_col)[target].mean()}), end='\\n\\n\\n')\n",
    "    if plot:\n",
    "        sns.barplot(x=categorical_col, y=target, data=dataframe)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    target_summary_with_cat(df, 'Survived', col, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_summary_with_num(dataframe, target, numerical_col, plot=False):\n",
    "    print(pd.DataFrame({numerical_col+'_mean': dataframe.groupby(target)[numerical_col].mean()}), end='\\n\\n\\n')\n",
    "    if plot:\n",
    "        sns.barplot(x=target, y=numerical_col, data=dataframe)\n",
    "        plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    target_summary_with_cat(df, 'Survived', col, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log1p(df[\"Survived\"]).hist(bins=50)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_correlated_cols(dataframe, plot=False, corr_th=0.70):\n",
    "    corr = dataframe.corr()\n",
    "    cor_matrix = corr.abs()\n",
    "    upper_triangle_matrix = cor_matrix.where(np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n",
    "    drop_list = [col for col in upper_triangle_matrix.columns if any(upper_triangle_matrix[col] > corr_th)]\n",
    "    if plot:\n",
    "        import seaborn as sns\n",
    "        import matplotlib.pyplot as plt\n",
    "        sns.set(rc={'figure.figsize': (12, 8)})\n",
    "        sns.heatmap(corr, cmap=\"RdBu\", annot=True, fmt=\".2f\")  # annot=True added here\n",
    "        plt.show()\n",
    "    return drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_correlated_cols(df, plot=True)\n",
    "corr = df[num_cols].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_counts = df['Survived'].value_counts()\n",
    "\n",
    "# Calculate the total number of passengers\n",
    "total_passengers = outcome_counts.sum()\n",
    "\n",
    "# Calculate the percentages\n",
    "percentages = outcome_counts / total_passengers * 100\n",
    "\n",
    "# Create labels with both quantity and percentage\n",
    "labels = [f'0 - Not Survived\\n({outcome_counts[0]} / {percentages[0]:.1f}%)',\n",
    "          f'1 - Survived\\n({outcome_counts[1]} / {percentages[1]:.1f}%)']\n",
    "\n",
    "# Plot the pie chart with labels and percentages\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(outcome_counts, labels=labels, autopct='%1.1f%%', colors=['purple', 'lightgray'])\n",
    "plt.title('Distribution of the Outcome Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.95):\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outlier(dataframe, col_name):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outlier(dataframe, col_name, plot=False):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, col_name)\n",
    "    outliers = dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)]\n",
    "    if outliers.any(axis=None):\n",
    "        if plot:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.boxplot(x=dataframe[col_name])\n",
    "            plt.title(f'Outliers in {col_name}')\n",
    "            plt.show()\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_thresholds(dataframe, variable, q1=0.05, q3=0.95):\n",
    "    low_limit, up_limit = outlier_thresholds(dataframe, variable, q1=0.05, q3=0.95)\n",
    "    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n",
    "    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Age', 'Fare']:\n",
    "    print(col, check_outlier(df, col, plot=True))\n",
    "    if check_outlier(df, col, plot=True):\n",
    "        replace_with_thresholds(df, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Age', 'Fare']:\n",
    "    print(col, check_outlier(df, col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TotalFamily\"] = df[\"SibSp\"] + df[\"Parch\"]\n",
    "df['Alone'] = (df['SibSp']==0) & (df['Parch']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bins= [0,2,17,65,100]\n",
    "labels = ['Baby','Child','Adult','Elderly']\n",
    "df['AgeGroup'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins= [-1,130,260,390,520]\n",
    "labels = ['Low','Medium','High','Very High']\n",
    "df['FareGroup'] = pd.cut(df['Fare'], bins=bins, labels=labels, right=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, num_cols, cat_but_car,  num_but_cat = grab_col_names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.remove(\"Survived\")\n",
    "cat_cols = ['Pclass', 'SibSp', 'Parch', 'TotalFamily', 'Alone', 'AgeGroup', 'FareGroup', 'Embarked', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_encoder(dataframe, binary_col):\n",
    "    labelencoder = LabelEncoder()\n",
    "    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [col for col in df.columns if df[col].dtypes == \"O\" and df[col].nunique() == 2]\n",
    "binary_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_cols:\n",
    "    df = label_encoder(df, col)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(dataframe, categorical_cols, drop_first=False):\n",
    "    dataframe = pd.get_dummies(dataframe, columns=categorical_cols, drop_first=drop_first)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encoder(df, cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Age', 'Fare']\n",
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:first_train]\n",
    "\n",
    "test_1 = df[first_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Survived']\n",
    "\n",
    "# Creating Independent Variables.\n",
    "\n",
    "X = train.drop('Survived', axis=1)\n",
    "\n",
    "# Splitting the Data into Training and Test Sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=1000)),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier()),\n",
    "    ('GaussianNB', GaussianNB()),\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier()),\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('AdaBoostClassifier', AdaBoostClassifier()),\n",
    "    ('BaggingClassifier', BaggingClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('XGBClassifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    ('SVC', SVC(probability=True))\n",
    "]\n",
    "\n",
    "# Train and evaluate models\n",
    "model_names = []\n",
    "accuracies = []\n",
    "train_accuracies=[]\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_train=model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    model_names.append(name)\n",
    "    accuracies.append(accuracy)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "model_performance = pd.DataFrame({'Model': model_names, 'Train Accuracy':train_accuracies, 'Test Accuracy':accuracies})\n",
    "model_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "acc_log = round(model.score(X_train, y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostRegressor(loss_function='RMSE', logging_level='Silent')\n",
    "cb_model.fit(X_train, y_train)\n",
    "preds = cb_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', metrics.mean_absolute_error(y_test, preds))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, preds))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, preds)))\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(random_state=46).fit(X_train, y_train)\n",
    "\n",
    "# Prediction using Random Forest Classifier Model\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "print(\"RandomForestClassifier:\")\n",
    "print(f\"Accuracy: {round(accuracy_score(y_pred, y_test), 4)}\")\n",
    "print(f\"Recall: {round(recall_score(y_pred,y_test),4)}\")\n",
    "print(f\"Precision: {round(precision_score(y_pred,y_test), 4)}\")\n",
    "print(f\"F1: {round(f1_score(y_pred,y_test), 4)}\")\n",
    "print(f\"Auc: {round(roc_auc_score(y_pred,y_test), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(model, features, num=len(X), save=False):\n",
    "    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    sns.set(font_scale=1)\n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[0:num])\n",
    "    plt.title(f'Feature Importance - {model.__class__.__name__}')\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)\n",
    "    if save:\n",
    "        plt.savefig('importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = [rf_model, dt_model, xgb_model, lgbm_model]\n",
    "for i in model_name:\n",
    "    plot_importance(i, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1=test_1.drop(\"Survived\",axis=1)\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub = model.predict(test_1)\n",
    "Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": sub_id,\n",
    "        \"Survived\": Sub\n",
    "    })\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def create_zip(source_path, zip_file_path):\n",
    "    with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        if os.path.isfile(source_path):\n",
    "            zipf.write(source_path, os.path.basename(source_path))\n",
    "        elif os.path.isdir(source_path):\n",
    "            for root, _, files in os.walk(source_path):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    arcname = os.path.relpath(file_path, source_path)\n",
    "                    zipf.write(file_path, arcname)\n",
    "\n",
    "source_path = 'catboost_info' \n",
    "zip_file_path = 'catboost_info.zip'  \n",
    "create_zip(source_path, zip_file_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
